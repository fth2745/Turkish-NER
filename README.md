
# ğŸ‡¹ğŸ‡· Multi-Task Turkish NER (BERT + BiLSTM)

Bu proje, TÃ¼rkÃ§e metinler iÃ§in geliÅŸmiÅŸ bir VarlÄ±k TanÄ±ma (NER) sistemi iÃ§erir. Model, BERT'in derin anlamsal anlama yeteneÄŸini BiLSTM'in sÄ±ralÄ± desen yakalama gÃ¼cÃ¼yle birleÅŸtirir. En temel Ã¶zelliÄŸi, standart B-I-O etiketlerini tahmin ederken aynÄ± anda bu varlÄ±klarÄ±n Ã¼st dÃ¼zey kategorilerini sÄ±nÄ±flandÄ±ran Ã§ok gÃ¶revli (multi-task) bir mimariye sahip olmasÄ±dÄ±r.

---

## ğŸš€ Temel Ã–zellikler ve Konseptler

### âœ… Ã‡ok GÃ¶revli Ã–ÄŸrenme (Multi-Task Learning)

Model, tek bir girdi Ã¼zerinden iki gÃ¶revi eÅŸ zamanlÄ± olarak Ã¶ÄŸrenir:

- **BIO Tespiti:** Kelimenin bir varlÄ±k baÅŸlangÄ±cÄ± (B), iÃ§i (I) ya da dÄ±ÅŸÄ± (O) olup olmadÄ±ÄŸÄ±nÄ± belirler.
- **VarlÄ±k SÄ±nÄ±flandÄ±rmasÄ±:** Tespit edilen varlÄ±ÄŸÄ±n KÄ°ÅÄ°, YER, KURUM vb. gibi Ã¼st dÃ¼zey kategorisini tahmin eder.

### ğŸ§± Hibrit Model Mimarisi

- **BERT**: [`dbmdz/bert-base-turkish-128k-cased`](https://huggingface.co/dbmdz/bert-base-turkish-128k-cased) modeli ile baÄŸlamsal kelime temsilleri Ã¼retilir.
- **BiLSTM**: BERT'ten gelen Ã§Ä±ktÄ±larla ileri ve geri yÃ¶nde sÄ±ralÄ± bilgi iÅŸlenir.

### â„ï¸ Dinamik Katman Dondurma

EÄŸer bir gÃ¶rev (Ã¶rneÄŸin BIO) iÃ§in doÄŸrulama kaybÄ± artarsa, o gÃ¶reve ait sÄ±nÄ±flandÄ±rÄ±cÄ± katman geÃ§ici olarak dondurulur. Bu, gÃ¶revler arasÄ± etkileÅŸimi dengeleyerek modelin kararlÄ±lÄ±ÄŸÄ±nÄ± artÄ±rÄ±r.

### ğŸ§² Triplet Loss ile GÃ¶mme (Embedding) Ã–ÄŸrenimi

AynÄ± kategoriye ait varlÄ±klarÄ±n gÃ¶mme uzayÄ±nda birbirine yakÄ±n, farklÄ± kategorilerin ise uzak olmasÄ± saÄŸlanÄ±r. Bu amaÃ§la `TripletMarginLoss` kullanÄ±lÄ±r.

### âš™ï¸ Verimli EÄŸitim Teknikleri

- **AMP (Mixed Precision Training):** Daha hÄ±zlÄ± ve bellek verimli eÄŸitim iÃ§in `torch.cuda.amp`.
- **BucketBatchSampler:** Benzer uzunluktaki cÃ¼mleler aynÄ± batch'e alÄ±narak padding azaltÄ±lÄ±r.
- **SÄ±nÄ±f DengesizliÄŸi:** `CrossEntropyLoss` iÃ§inde sÄ±nÄ±f aÄŸÄ±rlÄ±klarÄ± kullanÄ±larak Ã§Ã¶zÃ¼lÃ¼r.

---

## ğŸ§  Model Mimarisi

```
          Girdi CÃ¼mlesi (Tokenlar)
                      â†“
     Tokenization (BERT Tokenizer)
                      â†“
BERT (dbmdz/bert-base-turkish-128k-cased)
                      â†“
        Layer Normalization
                      â†“
         BiLSTM (2 KatmanlÄ±)
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                           â”‚
â†“                                           â†“
BIO SÄ±nÄ±flandÄ±rma Head             VarlÄ±k SÄ±nÄ±flandÄ±rma Head
(Dense -> ReLU -> Dropout ->       Dense -> ReLU -> Dropout ->
 Linear)                           Linear
â”‚                                           â”‚
â†“                                           â†“
BIO Logitleri (B, I, O)             VarlÄ±k Logitleri (KÄ°ÅÄ°, YER, ...)
â”‚                                           â”‚
â†“                                           â†“
BIO KaybÄ± (CrossEntropyLoss)       VarlÄ±k KaybÄ± + Triplet Loss
```

---

## ğŸ“‚ Veri Seti ve Ã–n Ä°ÅŸleme

Model `.jsonl` formatÄ±nda veri bekler. Her satÄ±r bir cÃ¼mleyi temsil eder.

### âœ… Beklenen Format

```json
{
  "tokens": ["Mustafa", "Kemal", "AtatÃ¼rk", "AnÄ±tkabir'de", "yatÄ±yor", "."],
  "ner_tags": ["B-person", "I-person", "I-person", "B-location", "O", "O"]
}
```

### ğŸ”§ Ã–n Ä°ÅŸleme AdÄ±mlarÄ±

1. **Etiket Gruplama:** Ã–rneÄŸin `B-government_person` gibi detaylÄ± etiketler `KÄ°ÅÄ°` gibi Ã¼st dÃ¼zey kategorilere indirgenir.
2. **Etiket AyÄ±rma:** Etiketler `bio_tags` ve `entity_tags` olmak Ã¼zere ikiye ayrÄ±lÄ±r.
3. **Tokenizasyon:** BERT tokenizer ile alt kelimelere ayrÄ±lÄ±r ve etiketler hizalanÄ±r.
4. **Maskeleme:** `O` etiketli ve dÃ¼ÅŸÃ¼k gÃ¼venli tahminler (`bio_threshold` altÄ±nda) `-100` ile maskelenir.

---

## ğŸ“Š DeÄŸerlendirme

- BIO ve Entity gÃ¶revleri ayrÄ± ayrÄ± deÄŸerlendirilir.
- AÅŸaÄŸÄ±daki metrikler her gÃ¶rev iÃ§in ayrÄ± hesaplanÄ±r:
  - Accuracy
  - Precision / Recall / F1 (macro average)
- `classification_report` ile B/I ve her sÄ±nÄ±f iÃ§in detaylÄ± sonuÃ§ sunulur.
- En iyi model test setinde yeniden deÄŸerlendirilir.

---

## ğŸ§© YapÄ±landÄ±rma Parametreleri

| Parametre | AÃ§Ä±klama |
|-----------|----------|
| `model_name` | KullanÄ±lacak BERT modeli adÄ±. |
| `max_length` | Tokenizer'Ä±n maksimum uzunluÄŸu. |
| `batch_size` | EÄŸitimde kullanÄ±lacak batch boyutu. |
| `learning_rate` | Ã–ÄŸrenme oranÄ±. |
| `num_epochs` | Toplam epoch sayÄ±sÄ±. |
| `early_stopping_patience` | DoÄŸrulama kaybÄ± iyileÅŸmezse eÄŸitimin durdurulacaÄŸÄ± epoch sayÄ±sÄ±. |
| `triplet_loss_weight` | TripletLoss'un toplam kayba katkÄ± oranÄ±. |
| `bio_freeze_patience` | BIO kaybÄ± bu kadar epoch artarsa BIO katmanÄ± dondurulur. |
| `bio_threshold` | B veya I tahmininin gÃ¼ven skoru bu eÅŸiÄŸin altÄ±ndaysa dikkate alÄ±nmaz. |

---

## â“ Neden `O` Etiketi Ä°Ã§in Ã–zel Ä°ÅŸlem YapÄ±yoruz?

Ã‡oÄŸu NER veri kÃ¼mesinde "O" (Outside) etiketi, B ve I etiketlerine gÃ¶re Ã§ok daha fazladÄ±r. Bu durum sÄ±nÄ±f dengesizliÄŸine yol aÃ§ar. Bizim yaklaÅŸÄ±mÄ±mÄ±z:

- `O` etiketli tokenlarÄ±n bir kÄ±smÄ±nÄ± kayÄ±p fonksiyonundan dÄ±ÅŸlamak,
- Bu dÄ±ÅŸlamayÄ± tahminin dÃ¼ÅŸÃ¼k gÃ¼venli (Ã¶rneÄŸin softmax skoru dÃ¼ÅŸÃ¼k) olmasÄ± durumunda yapmak,
- BÃ¶ylece modelin sadece emin olduÄŸu B/I tahminlerine odaklanmasÄ±nÄ± saÄŸlamak.

### ğŸ“ˆ Model GeliÅŸimi: Ã–ncesi ve SonrasÄ± KarÅŸÄ±laÅŸtÄ±rmasÄ±

#### ğŸ“Š BIO Classification Report (B ve I Etiketleri)

**Ã–nce (Epoch 8 / O Etiketi Dahil):**
```
           B       0.61      0.92      0.73    111899
           I       0.47      0.94      0.62     32364
           O       0.99      0.87      0.93    708037
accuracy: 0.88 | macro avg f1: 0.76
```

**Sonra (Sadece B ve I):**
```
           B       0.99      0.92      0.95    111899
           I       0.78      0.97      0.86     32364
accuracy: 0.93 | macro avg f1: 0.91
```

âœ… **Ä°yileÅŸme Ã–zeti:**  
- `B` iÃ§in F1: **%73 â†’ %95**  
- `I` iÃ§in F1: **%62 â†’ %86**  
- Genel makro ortalama F1: **%76 â†’ %91**

---

#### ğŸ“Š Entity Classification Report (O Etiketi HariÃ§)

**Ã–nce:**
```
macro avg f1: 0.91 | weighted avg f1: 0.92
Ã–ne Ã§Ä±kan sÄ±nÄ±f Ã¶rneÄŸi â†’ BÄ°LÄ°M_KÃœLTÃœR: F1 0.84
```

**Sonra:**
```
macro avg f1: 0.92 | weighted avg f1: 0.92
Ã–ne Ã§Ä±kan sÄ±nÄ±f Ã¶rneÄŸi â†’ BÄ°LÄ°M_KÃœLTÃœR: F1 0.91
```

âœ… **Ä°yileÅŸme Ã–zeti:**
- Genel olarak F1 skorlarÄ±nda artÄ±ÅŸ.
- En zayÄ±f sÄ±nÄ±flardan biri olan `BÄ°LÄ°M_KÃœLTÃœR` sÄ±nÄ±fÄ±nda **%84 â†’ %91** yÃ¼kseliÅŸ.
- Bu durum, hem entity headâ€™in hem embedding yapÄ±sÄ±nÄ±n daha saÄŸlam hale geldiÄŸini gÃ¶steriyor.

---

#### ğŸ“‰ KayÄ±p ve DoÄŸruluk KarÅŸÄ±laÅŸtÄ±rmasÄ±

|            | BIO Loss | ENT Loss | BIO Acc | ENT Acc |
|------------|----------|----------|---------|----------|
| **Ã–nce**   | 0.3615   | 0.2879   | 0.7613  | 0.9094   |
| **Sonra**  | 0.1785   | 0.2724   | 0.9300  | 0.9200   |

> BIO taskâ€™inde hem doÄŸruluk hem kayÄ±p dÃ¼zeyinde **belirgin bir iyileÅŸme** gÃ¶zleniyor.

---

### ğŸ“Œ Neden "O Etiketi HariÃ§" DeÄŸerlendirme YaptÄ±k?

- `O` etiketi modelin **varlÄ±k dÄ±ÅŸÄ± kelimeleri** ne kadar iyi ayÄ±kladÄ±ÄŸÄ±nÄ± gÃ¶sterir.
- Ancak `O` sÄ±nÄ±fÄ± genellikle Ã§ok baskÄ±ndÄ±r (Ã¶rnek: 700k vs 100k). Bu, genel skoru yapay olarak yÃ¼kseltebilir.
- Bu yÃ¼zden sadece `B` ve `I` etiketlerine odaklanmak, modelin gerÃ§ekten varlÄ±k tespit etme kabiliyetini Ã¶lÃ§er.
- AynÄ± ÅŸekilde, entity classification'da da sadece **anlamlÄ± varlÄ±k etiketleri** deÄŸerlendirilmelidir.
- 
> Bu strateji modelin **varlÄ±k sÄ±nÄ±rlarÄ±nÄ± daha isabetli belirlemesini**, **false positive'leri azaltmasÄ±nÄ±** ve **daha hÄ±zlÄ± Ã¶ÄŸrenmesini** saÄŸlar.



