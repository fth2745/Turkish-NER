
# ğŸ‡¹ğŸ‡· Multi-Task Turkish NER (BERT + BiLSTM)

Bu proje, TÃ¼rkÃ§e metinler iÃ§in geliÅŸmiÅŸ bir VarlÄ±k TanÄ±ma (NER) sistemi iÃ§erir. Model, BERT'in derin anlamsal anlama yeteneÄŸini BiLSTM'in sÄ±ralÄ± desen yakalama gÃ¼cÃ¼yle birleÅŸtirir. En temel Ã¶zelliÄŸi, standart B-I-O etiketlerini tahmin ederken aynÄ± anda bu varlÄ±klarÄ±n Ã¼st dÃ¼zey kategorilerini sÄ±nÄ±flandÄ±ran Ã§ok gÃ¶revli (multi-task) bir mimariye sahip olmasÄ±dÄ±r.

---

## ğŸš€ Temel Ã–zellikler ve Konseptler

### âœ… Ã‡ok GÃ¶revli Ã–ÄŸrenme (Multi-Task Learning)

Model, tek bir girdi Ã¼zerinden iki gÃ¶revi eÅŸ zamanlÄ± olarak Ã¶ÄŸrenir:

- **BIO Tespiti:** Kelimenin bir varlÄ±k baÅŸlangÄ±cÄ± (B), iÃ§i (I) ya da dÄ±ÅŸÄ± (O) olup olmadÄ±ÄŸÄ±nÄ± belirler.
- **VarlÄ±k SÄ±nÄ±flandÄ±rmasÄ±:** Tespit edilen varlÄ±ÄŸÄ±n KÄ°ÅÄ°, YER, KURUM vb. gibi Ã¼st dÃ¼zey kategorisini tahmin eder.

### ğŸ§± Hibrit Model Mimarisi

- **BERT**: [`dbmdz/bert-base-turkish-128k-cased`](https://huggingface.co/dbmdz/bert-base-turkish-128k-cased) modeli ile baÄŸlamsal kelime temsilleri Ã¼retilir.
- **BiLSTM**: BERT'ten gelen Ã§Ä±ktÄ±larla ileri ve geri yÃ¶nde sÄ±ralÄ± bilgi iÅŸlenir.

### â„ï¸ Dinamik Katman Dondurma

EÄŸer bir gÃ¶rev (Ã¶rneÄŸin BIO) iÃ§in doÄŸrulama kaybÄ± artarsa, o gÃ¶reve ait sÄ±nÄ±flandÄ±rÄ±cÄ± katman geÃ§ici olarak dondurulur. Bu, gÃ¶revler arasÄ± etkileÅŸimi dengeleyerek modelin kararlÄ±lÄ±ÄŸÄ±nÄ± artÄ±rÄ±r.

### ğŸ§² Triplet Loss ile GÃ¶mme (Embedding) Ã–ÄŸrenimi

AynÄ± kategoriye ait varlÄ±klarÄ±n gÃ¶mme uzayÄ±nda birbirine yakÄ±n, farklÄ± kategorilerin ise uzak olmasÄ± saÄŸlanÄ±r. Bu amaÃ§la `TripletMarginLoss` kullanÄ±lÄ±r.

### âš™ï¸ Verimli EÄŸitim Teknikleri

- **AMP (Mixed Precision Training):** Daha hÄ±zlÄ± ve bellek verimli eÄŸitim iÃ§in `torch.cuda.amp`.
- **BucketBatchSampler:** Benzer uzunluktaki cÃ¼mleler aynÄ± batch'e alÄ±narak padding azaltÄ±lÄ±r.
- **SÄ±nÄ±f DengesizliÄŸi:** `CrossEntropyLoss` iÃ§inde sÄ±nÄ±f aÄŸÄ±rlÄ±klarÄ± kullanÄ±larak Ã§Ã¶zÃ¼lÃ¼r.

---

## ğŸ§  Model Mimarisi

```
          Girdi CÃ¼mlesi (Tokenlar)
                      â†“
     Tokenization (BERT Tokenizer)
                      â†“
BERT (dbmdz/bert-base-turkish-128k-cased)
                      â†“
        Layer Normalization
                      â†“
         BiLSTM (2 KatmanlÄ±)
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                           â”‚
â†“                                           â†“
BIO SÄ±nÄ±flandÄ±rma Head             VarlÄ±k SÄ±nÄ±flandÄ±rma Head
(Dense -> ReLU -> Dropout ->       Dense -> ReLU -> Dropout ->
 Linear)                           Linear
â”‚                                           â”‚
â†“                                           â†“
BIO Logitleri (B, I, O)             VarlÄ±k Logitleri (KÄ°ÅÄ°, YER, ...)
â”‚                                           â”‚
â†“                                           â†“
BIO KaybÄ± (CrossEntropyLoss)       VarlÄ±k KaybÄ± + Triplet Loss
```

---

## ğŸ“‚ Veri Seti ve Ã–n Ä°ÅŸleme

Model `.jsonl` formatÄ±nda veri bekler. Her satÄ±r bir cÃ¼mleyi temsil eder.

### âœ… Beklenen Format

```json
{
  "tokens": ["Mustafa", "Kemal", "AtatÃ¼rk", "AnÄ±tkabir'de", "yatÄ±yor", "."],
  "ner_tags": ["B-person", "I-person", "I-person", "B-location", "O", "O"]
}
```

### ğŸ”§ Ã–n Ä°ÅŸleme AdÄ±mlarÄ±

1. **Etiket Gruplama:** Ã–rneÄŸin `B-government_person` gibi detaylÄ± etiketler `KÄ°ÅÄ°` gibi Ã¼st dÃ¼zey kategorilere indirgenir.
2. **Etiket AyÄ±rma:** Etiketler `bio_tags` ve `entity_tags` olmak Ã¼zere ikiye ayrÄ±lÄ±r.
3. **Tokenizasyon:** BERT tokenizer ile alt kelimelere ayrÄ±lÄ±r ve etiketler hizalanÄ±r.
4. **Maskeleme:** `O` etiketli ve dÃ¼ÅŸÃ¼k gÃ¼venli tahminler (`bio_threshold` altÄ±nda) `-100` ile maskelenir.

---

## âš™ï¸ Kurulum ve KullanÄ±m

### 1. Projeyi KlonlayÄ±n

```bash
git clone https://github.com/kullanici/proje-adi.git
cd proje-adi
```

### 2. Gerekli KÃ¼tÃ¼phaneleri YÃ¼kleyin

```bash
pip install torch pandas numpy transformers scikit-learn torch-optimizer
```

> Not: `requirements.txt` dosyasÄ± kullanmanÄ±z Ã¶nerilir.

### 3. Veri Setini HazÄ±rlayÄ±n

Veri setinizi yukarÄ±da aÃ§Ä±klanan `.jsonl` formatÄ±nda hazÄ±rlayÄ±n. `main()` fonksiyonu iÃ§inde dosya yolunu aÅŸaÄŸÄ±daki ÅŸekilde dÃ¼zenleyin:

```python
full_data = load_dataset_from_json(
    "path/to/your/dataset.jsonl",
    config["tokens_col"],
    config["tags_col"],
    entity_group_map=entity_group_map
)
```

### 4. YapÄ±landÄ±rmayÄ± DÃ¼zenleyin

```python
config = {
    "model_name": "dbmdz/bert-base-turkish-128k-cased",
    "max_length": 128,
    "batch_size": 16,
    "learning_rate": 3e-5,
    "num_epochs": 10,
    ...
}
```

### 5. EÄŸitimi BaÅŸlatÄ±n

```bash
python ner_trainer.py
```

---

## ğŸ“Š DeÄŸerlendirme

- BIO ve Entity gÃ¶revleri ayrÄ± ayrÄ± deÄŸerlendirilir.
- AÅŸaÄŸÄ±daki metrikler her gÃ¶rev iÃ§in ayrÄ± hesaplanÄ±r:
  - Accuracy
  - Precision / Recall / F1 (macro average)
- `classification_report` ile B/I ve her sÄ±nÄ±f iÃ§in detaylÄ± sonuÃ§ sunulur.
- En iyi model test setinde yeniden deÄŸerlendirilir.

---

## ğŸ§© YapÄ±landÄ±rma Parametreleri

| Parametre | AÃ§Ä±klama |
|-----------|----------|
| `model_name` | KullanÄ±lacak BERT modeli adÄ±. |
| `max_length` | Tokenizer'Ä±n maksimum uzunluÄŸu. |
| `batch_size` | EÄŸitimde kullanÄ±lacak batch boyutu. |
| `learning_rate` | Ã–ÄŸrenme oranÄ±. |
| `num_epochs` | Toplam epoch sayÄ±sÄ±. |
| `early_stopping_patience` | DoÄŸrulama kaybÄ± iyileÅŸmezse eÄŸitimin durdurulacaÄŸÄ± epoch sayÄ±sÄ±. |
| `triplet_loss_weight` | TripletLoss'un toplam kayba katkÄ± oranÄ±. |
| `bio_freeze_patience` | BIO kaybÄ± bu kadar epoch artarsa BIO katmanÄ± dondurulur. |
| `bio_threshold` | B veya I tahmininin gÃ¼ven skoru bu eÅŸiÄŸin altÄ±ndaysa dikkate alÄ±nmaz. |

---

## â“ Neden `O` Etiketi Ä°Ã§in Ã–zel Ä°ÅŸlem YapÄ±yoruz?

Ã‡oÄŸu NER veri kÃ¼mesinde "O" (Outside) etiketi, B ve I etiketlerine gÃ¶re Ã§ok daha fazladÄ±r. Bu durum sÄ±nÄ±f dengesizliÄŸine yol aÃ§ar. Bizim yaklaÅŸÄ±mÄ±mÄ±z:

- `O` etiketli tokenlarÄ±n bir kÄ±smÄ±nÄ± kayÄ±p fonksiyonundan dÄ±ÅŸlamak,
- Bu dÄ±ÅŸlamayÄ± tahminin dÃ¼ÅŸÃ¼k gÃ¼venli (Ã¶rneÄŸin softmax skoru dÃ¼ÅŸÃ¼k) olmasÄ± durumunda yapmak,
- BÃ¶ylece modelin sadece emin olduÄŸu B/I tahminlerine odaklanmasÄ±nÄ± saÄŸlamak.

> Bu strateji modelin **varlÄ±k sÄ±nÄ±rlarÄ±nÄ± daha isabetli belirlemesini**, **false positive'leri azaltmasÄ±nÄ±** ve **daha hÄ±zlÄ± Ã¶ÄŸrenmesini** saÄŸlar.


